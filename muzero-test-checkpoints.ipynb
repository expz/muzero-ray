{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.putenv('TF_CPP_MIN_LOG_LEVEL', '2')\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import logging\n",
    "import ray\n",
    "from ray import tune\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from muzero.env import wrap_muzero, register_muzero_env\n",
    "from muzero.muzero import ATARI_DEFAULT_CONFIG\n",
    "from muzero.trainer import MuZeroTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-13 12:26:11,525\tINFO resource_spec.py:231 -- Starting Ray with 32.67 GiB memory available for workers and up to 20.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-13 12:26:11,957\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.128.128',\n",
       " 'raylet_ip_address': '10.0.128.128',\n",
       " 'redis_address': '10.0.128.128:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-02-13_12-26-11_494403_114141/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-02-13_12-26-11_494403_114141/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-02-13_12-26-11_494403_114141'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def update_config(old_config, new_config):\n",
    "    config = {**old_config}\n",
    "    for k, v in new_config.items():\n",
    "        if k in config and isinstance(v, dict):\n",
    "            config[k] = update_config(config[k], v)\n",
    "        else:\n",
    "            config[k] = v\n",
    "    return config\n",
    "\n",
    "env_name = 'BreakoutNoFrameskip-MuZero-v1'\n",
    "\n",
    "config = {\n",
    "    'env': env_name,\n",
    "    'action_type': 'atari',\n",
    "    'num_workers': 4,\n",
    "    'num_gpus': 1,\n",
    "    'num_cpus_per_worker': 2,\n",
    "    'num_gpus_per_worker': 0,\n",
    "    'memory_per_worker': 6 * 1024**3,\n",
    "    'object_store_memory_per_worker': 3 * 1024**3,\n",
    "    'log_level': 'ERROR',\n",
    "    'learning_starts': 256,\n",
    "    'timesteps_per_iteration': 512,\n",
    "    'buffer_size': 100000,\n",
    "    'mcts': {\n",
    "        'reset_q_bounds_per_node': True,\n",
    "        'add_dirichlet_noise': True,\n",
    "        'dirichlet_epsilon': 0.25,\n",
    "        'dirichlet_alpha': 0.25,\n",
    "        # The paper used 50, but showed that it could work with as little as 7\n",
    "        'num_simulations': 20,\n",
    "        'argmax_tree_policy': False,\n",
    "        'puct_c1': 1.25,\n",
    "        'puct_c2': 19652,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'num_replay_buffer_shards': 1,\n",
    "        'debug': False,\n",
    "    },\n",
    "}\n",
    "config = update_config(ATARI_DEFAULT_CONFIG, config)\n",
    "\n",
    "register_muzero_env('BreakoutNoFrameskip-v4', env_name)\n",
    "\n",
    "try:\n",
    "    ray.shutdown()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#ray.init(local_mode=True)\n",
    "ray.init(\n",
    "    num_cpus=9,\n",
    "    num_gpus=0,\n",
    "    object_store_memory=20 * 1024**3,\n",
    "    #_redis_max_memory=5 * 1024**3,\n",
    "    #_memory=25 * 1024**3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=114203)\u001b[0m 2021-02-13 12:26:16.945401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:16.959459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:17.010357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:16.994469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:16.982756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.274984: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.275769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.279494: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.280316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.307658: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.308391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315604: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315646: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315786: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.315827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.328301: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m 2021-02-13 12:26:18.328534: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323449: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323487: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.323654: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.333553: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m 2021-02-13 12:26:18.333745: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338567: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338615: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.338827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.351813: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m 2021-02-13 12:26:18.351993: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.369820: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.370616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.378721: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.378784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.378792: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: country-house.pier.ai\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.378968: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.379008: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.379018: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.102.4\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.389994: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m 2021-02-13 12:26:18.390195: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=114199)\u001b[0m Worker 4 initialized.\n",
      "\u001b[2m\u001b[36m(pid=114196)\u001b[0m Worker 3 initialized.\n",
      "\u001b[2m\u001b[36m(pid=114197)\u001b[0m Worker 1 initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trial = 'MuZeroTrainer_BreakoutNoFrameskip-MuZero-v1_0_2021-01-03_14-22-11hhh589cz'\n",
    "checkpoint = 38\n",
    "\n",
    "trainer = MuZeroTrainer(config, env_name)\n",
    "trainer.load_checkpoint(f'./results/breakout/{trial}/checkpoint_{checkpoint}/checkpoint-{checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=114200)\u001b[0m Worker 2 initialized.\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "from xvfbwrapper import Xvfb\n",
    "import numpy as np\n",
    "import time\n",
    "import pyglet\n",
    "import gym\n",
    "import PIL.Image\n",
    "import io    \n",
    "\n",
    "from ray.rllib.env.atari_wrappers import MonitorEnv, NoopResetEnv, FireResetEnv, EpisodicLifeEnv, WarpFrame, FrameStack\n",
    "from ray.rllib.env.atari_wrappers import wrap_deepmind\n",
    "\n",
    "\n",
    "def play(env_name, agent, steps=1000):\n",
    "    policy = agent.get_policy()\n",
    "    \n",
    "    vdisplay = Xvfb(width=1280, height=740)\n",
    "    vdisplay.start()\n",
    "\n",
    "    env = wrap_muzero(gym.make(env_name))\n",
    "    #prep = get_preprocessor(env.observation_space)(env.observation_space, {'grayscale': True, 'zero_mean': False, 'dim': 84})\n",
    "    observation = env.reset()\n",
    "    #four_frames = [prep.transform(observation) for _ in range(3)]\n",
    "    #action = 1\n",
    "    #observation, reward, done, info = env.step(action)\n",
    "    #four_frames.append(prep.transform(observation))\n",
    "    #for i in range(4):\n",
    "    #    four_frames.append(prep.transform(observation))\n",
    "    #    action = policy.action_space.sample()\n",
    "    #    observation, reward, done, info = env.step(action)\n",
    "    #full_obs = tf.concat(four_frames, axis=2)\n",
    "\n",
    "    def showarray(a, fmt='png'):\n",
    "        a = np.uint8(a)\n",
    "        f = io.BytesIO()\n",
    "        ima = PIL.Image.fromarray(a).save(f, fmt)\n",
    "        return f.getvalue()\n",
    "\n",
    "    imagehandle = display.display(display.Image(data=showarray(env.render(mode='rgb_array')), width=450), display_id='gymscr')\n",
    "\n",
    "    action = 0\n",
    "    reward = 0\n",
    "    for _ in range(steps):\n",
    "        time.sleep(0.001)\n",
    "        action = policy.compute_action(observation, greedy=False)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        #del four_frames[0]\n",
    "        #four_frames.append(prep.transform(observation))\n",
    "        #full_obs = tf.concat(four_frames, axis=2)\n",
    "        \n",
    "        display.update_display(display.Image(data=showarray(env.render(mode='rgb_array')), width=450), display_id='gymscr')\n",
    "        if done: break\n",
    "\n",
    "    vdisplay.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAAC30lEQVR4nO3dMW4TURRA0QSlRqyAioIlRJQU0RQsgjV4IVkGK6CwUlAiLwZRIERBEdGm8Aebscf2zTnlyJn51vVzvhTHc3UFAMDBXS95sfv7+38+ZrVaLfb4fT09/+i6c86/y7X29eIQi+F83ZzqwseY1NErfZfzV5nguJNN8DEsOamX8q5gguNSE/zUoXazu5zznKfZBMedbIL3fdUf6vHHmOxzZoIBztb1Oe8Amc/v4DiB4wSOEzhO4DiB4wSOEzhO4DiB4wSOEzhO4DiB44Yf2XluH225dKM/+5rgOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOG74wffNNC25Dmb6OjhuguMEjhM4TuA4geOGu+jHNz+WXAdHYoLjBI4TOE7gOIHjhrvo7y9/LbkOjsQExwkcJ3CcwHECx4130W9/L7kO5vq2/bAJjhM4TuA4geMEjhvuoj89vl5yHcx0NzhuguMEjhM4TuA4geOGu+j1x/XW4++nzdEWs4Qv69utxy/9eV3dbf//QhMcJ3CcwHECxwkcN9xFj4x2oZfu0p/Xhzs3p3yWBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4T+AJspmkzTf/3swLHCRwncNzeX+HA8m7X27+UbhcmOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI4TOE7gOIHjBI67+fzq56nXcL72vS3znLtIzvTu4WHrcRMcJ3CcwHFuEP03J/ydeigmOM4ERwTebAAAAAAAAFjcH/9KVCGatEMiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 450
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "play('BreakoutNoFrameskip-v4', trainer, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
